# import streamlit as st
# import openai
# import base64
# from io import BytesIO
# import os

# openai.api_key = os.environ.get("OPENAI_API_KEY", "YOUR_OPENAI_API_KEY")

# st.title("ğŸ¤ éŒ²éŸ³ã—ã¦æ–‡å­—èµ·ã“ã—ï¼†è¦ç´„ï¼ˆä¿®æ­£ç‰ˆï¼‰")

# st.write("éŒ²éŸ³é–‹å§‹ãƒ»åœæ­¢ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨éŒ²éŸ³ã—ã€éŒ²éŸ³çµ‚äº†å¾Œã«è‡ªå‹•çš„ã«æ–‡å­—èµ·ã“ã—ï¼†è¦ç´„ã—ã¾ã™ã€‚")

# # JSã‚³ãƒ¼ãƒ‰ï¼ˆéŒ²éŸ³ã€base64å¤‰æ›ã€çµ‚äº†æ™‚ã«base64æ–‡å­—åˆ—ã‚’è¿”ã™ï¼‰
# recording_js = """
# <script>
# let mediaRecorder;
# let audioChunks = [];
# let timerInterval;

# function startRecording() {
#     navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
#         mediaRecorder = new MediaRecorder(stream);
#         mediaRecorder.start();
#         audioChunks = [];
#         let startTime = Date.now();
#         document.getElementById("timer").innerText = "â±ï¸ éŒ²éŸ³ä¸­: 0 ç§’";
#         timerInterval = setInterval(() => {
#             let elapsed = Math.floor((Date.now() - startTime) / 1000);
#             document.getElementById("timer").innerText = `â±ï¸ éŒ²éŸ³ä¸­: ${elapsed} ç§’`;
#         }, 1000);

#         mediaRecorder.ondataavailable = e => {
#             audioChunks.push(e.data);
#         };

#         mediaRecorder.onstop = () => {
#             clearInterval(timerInterval);
#             document.getElementById("timer").innerText = "ğŸ›‘ éŒ²éŸ³åœæ­¢";

#             const audioBlob = new Blob(audioChunks, {type: 'audio/wav'});
#             const reader = new FileReader();
#             reader.readAsDataURL(audioBlob);
#             reader.onloadend = () => {
#                 const base64data = reader.result;
#                 // base64æ–‡å­—åˆ—ã‚’Streamlitå´ã«è¿”ã™
#                 const streamlitAPI = window.parent.streamlitAPI || window.parent.parent.streamlitAPI;
#                 if(streamlitAPI && streamlitAPI.setComponentValue) {
#                     streamlitAPI.setComponentValue(base64data);
#                 }
#             };

#             const audioUrl = URL.createObjectURL(audioBlob);
#             const audioElement = document.getElementById("audio_play");
#             audioElement.src = audioUrl;
#             audioElement.style.display = "block";
#         };
#     });
# }

# function stopRecording() {
#     if (mediaRecorder && mediaRecorder.state === "recording") {
#         mediaRecorder.stop();
#     }
# }
# </script>

# <div style="margin-top: 10px;">
#     <button onclick="startRecording()">ğŸ™ï¸ éŒ²éŸ³é–‹å§‹</button>
#     <button onclick="stopRecording()" style="margin-left: 10px;">â¹ï¸ éŒ²éŸ³åœæ­¢</button>
#     <h4 id="timer">â±ï¸ éŒ²éŸ³å‰</h4>
# </div>
# <audio id="audio_play" controls style="display:none; margin-top: 10px;"></audio>
# """

# # components.v1.html ã®æˆ»ã‚Šå€¤ã§JSã‹ã‚‰base64ã‚’å—ã‘å–ã‚‹
# audio_base64 = st.components.v1.html(recording_js, height=300, scrolling=False)

# if audio_base64:
#     st.audio(audio_base64, format="audio/wav")
#     st.write("ğŸŸ¢ éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å—ä¿¡ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")

#     with st.spinner("æ–‡å­—èµ·ã“ã—ï¼†è¦ç´„ä¸­...ãŠå¾…ã¡ãã ã•ã„ã€‚"):
#         try:
#             header, encoded = audio_base64.split(",", 1)
#             audio_bytes = base64.b64decode(encoded)
#             audio_file = BytesIO(audio_bytes)

#             transcript = openai.Audio.transcribe("whisper-1", audio_file)
#             st.write("### ğŸ“ æ–‡å­—èµ·ã“ã—çµæœ")
#             st.write(transcript["text"])

#             response = openai.ChatCompletion.create(
#                 model="gpt-4o-mini",
#                 messages=[
#                     {"role": "system", "content": "ä»¥ä¸‹ã®æ–‡ç« ã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚"},
#                     {"role": "user", "content": transcript["text"]},
#                 ],
#                 max_tokens=200,
#                 temperature=0.5,
#             )
#             summary = response["choices"][0]["message"]["content"]
#             st.write("### âœ¨ è¦ç´„")
#             st.write(summary)

#         except Exception as e:
#             st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

