import streamlit as st
import openai
from io import BytesIO
import os
import base64

openai.api_key = os.environ.get("OPENAI_API_KEY", "YOUR_OPENAI_API_KEY")

st.title("ğŸ¤ éŒ²éŸ³ã—ã¦æ–‡å­—èµ·ã“ã—ï¼†è¦ç´„")

st.write("""
ä»¥ä¸‹ã®ãƒœã‚¿ãƒ³ã§éŒ²éŸ³ã‚’é–‹å§‹ãƒ»åœæ­¢ã—ã¦ãã ã•ã„ã€‚  
åœæ­¢ã™ã‚‹ã¨éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã€æ–‡å­—èµ·ã“ã—ã¨è¦ç´„ãŒè¡Œã‚ã‚Œã¾ã™ã€‚
""")

# HTML + JS ã§éŒ²éŸ³ + ã‚¿ã‚¤ãƒãƒ¼ä»˜ãUI
recording_js = """
<script>
let mediaRecorder;
let audioChunks = [];
let timerInterval;

function startRecording() {
    navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
        mediaRecorder = new MediaRecorder(stream);
        mediaRecorder.start();
        audioChunks = [];

        // éŒ²éŸ³æ™‚é–“ã‚¿ã‚¤ãƒãƒ¼
        let startTime = Date.now();
        document.getElementById("timer").innerText = "â±ï¸ éŒ²éŸ³ä¸­: 0 ç§’";

        timerInterval = setInterval(() => {
            let elapsed = Math.floor((Date.now() - startTime) / 1000);
            document.getElementById("timer").innerText = `â±ï¸ éŒ²éŸ³ä¸­: ${elapsed} ç§’`;
        }, 1000);

        mediaRecorder.addEventListener("dataavailable", event => {
            audioChunks.push(event.data);
        });

        mediaRecorder.addEventListener("stop", () => {
            clearInterval(timerInterval);
            document.getElementById("timer").innerText = "ğŸ›‘ éŒ²éŸ³åœæ­¢";

            const audioBlob = new Blob(audioChunks, {type: 'audio/wav'});
            const audioUrl = URL.createObjectURL(audioBlob);
            const audioElement = document.getElementById("audio_play");
            audioElement.src = audioUrl;
            audioElement.style.display = "block";

            // Streamlitã¸ãƒ•ã‚¡ã‚¤ãƒ«é€ä¿¡
            const reader = new FileReader();
            reader.readAsDataURL(audioBlob);
            reader.onloadend = () => {
                const base64data = reader.result;
                const el = window.parent.document.getElementById("audio_data_textarea");
                el.value = base64data;
                el.dispatchEvent(new Event('input'));
            };
        });
    });
}

function stopRecording() {
    if (mediaRecorder && mediaRecorder.state === "recording") {
        mediaRecorder.stop();
    }
}
</script>

<div style="margin-top: 10px;">
    <button onclick="startRecording()">ğŸ™ï¸ éŒ²éŸ³é–‹å§‹</button>
    <button onclick="stopRecording()" style="margin-left: 10px;">â¹ï¸ éŒ²éŸ³åœæ­¢</button>
    <h4 id="timer">â±ï¸ éŒ²éŸ³å‰</h4>
</div>
<audio id="audio_play" controls style="display:none; margin-top: 10px;"></audio>
"""

st.components.v1.html(recording_js, height=200)

# éŸ³å£°ãƒ‡ãƒ¼ã‚¿å—ã‘å–ã‚Šç”¨ï¼ˆéè¡¨ç¤ºï¼‰
audio_base64 = st.text_area("audio_data_textarea", value="", height=10, key="audio_data_textarea")

# éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒæ¥ãŸã‚‰å‡¦ç†
if audio_base64:
    st.audio(audio_base64, format="audio/wav")

    header, encoded = audio_base64.split(",", 1)
    audio_bytes = base64.b64decode(encoded)

    with BytesIO(audio_bytes) as audio_file:
        transcript = openai.Audio.transcribe("whisper-1", audio_file)

    st.write("### ğŸ“ æ–‡å­—èµ·ã“ã—çµæœ")
    st.write(transcript["text"])

    response = openai.ChatCompletion.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ä»¥ä¸‹ã®æ–‡ç« ã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚"},
            {"role": "user", "content": transcript["text"]},
        ],
        max_tokens=200,
        temperature=0.5,
    )
    summary = response["choices"][0]["message"]["content"]
    st.write("### âœ¨ è¦ç´„")
    st.write(summary)
