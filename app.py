import streamlit as st
import openai
from io import BytesIO
import os
import base64
import time

openai.api_key = os.environ.get("OPENAI_API_KEY", "YOUR_OPENAI_API_KEY")

st.title("ğŸ¤ éŒ²éŸ³ã—ã¦æ–‡å­—èµ·ã“ã—ï¼†è¦ç´„")

st.write("""
ä»¥ä¸‹ã®ãƒœã‚¿ãƒ³ã§éŒ²éŸ³ã‚’é–‹å§‹ãƒ»åœæ­¢ã—ã¦ãã ã•ã„ã€‚  
åœæ­¢ã™ã‚‹ã¨éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã€æ–‡å­—èµ·ã“ã—ã¨è¦ç´„ãŒè¡Œã‚ã‚Œã¾ã™ã€‚
""")

recording_js = """
<script>
let mediaRecorder;
let audioChunks = [];
let timerInterval;

function startRecording() {
    navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
        mediaRecorder = new MediaRecorder(stream);
        mediaRecorder.start();
        audioChunks = [];

        let startTime = Date.now();
        document.getElementById("timer").innerText = "â±ï¸ éŒ²éŸ³ä¸­: 0 ç§’";

        timerInterval = setInterval(() => {
            let elapsed = Math.floor((Date.now() - startTime) / 1000);
            document.getElementById("timer").innerText = `â±ï¸ éŒ²éŸ³ä¸­: ${elapsed} ç§’`;
        }, 1000);

        mediaRecorder.addEventListener("dataavailable", event => {
            audioChunks.push(event.data);
        });

        mediaRecorder.addEventListener("stop", () => {
            clearInterval(timerInterval);
            document.getElementById("timer").innerText = "ğŸ›‘ éŒ²éŸ³åœæ­¢";

            const audioBlob = new Blob(audioChunks, {type: 'audio/wav'});
            const audioUrl = URL.createObjectURL(audioBlob);
            const audioElement = document.getElementById("audio_play");
            audioElement.src = audioUrl;
            audioElement.style.display = "block";

            const reader = new FileReader();
            reader.readAsDataURL(audioBlob);
            reader.onloadend = () => {
                const base64data = reader.result;
                const el = window.parent.document.getElementById("audio_data_textarea");
                el.value = base64data;
                el.dispatchEvent(new Event('input'));
            };
        });
    });
}

function stopRecording() {
    if (mediaRecorder && mediaRecorder.state === "recording") {
        mediaRecorder.stop();
    }
}
</script>

<div style="margin-top: 10px;">
    <button onclick="startRecording()">ğŸ™ï¸ éŒ²éŸ³é–‹å§‹</button>
    <button onclick="stopRecording()" style="margin-left: 10px;">â¹ï¸ éŒ²éŸ³åœæ­¢</button>
    <h4 id="timer">â±ï¸ éŒ²éŸ³å‰</h4>
</div>
<audio id="audio_play" controls style="display:none; margin-top: 10px;"></audio>
"""

st.components.v1.html(recording_js, height=250)

# éè¡¨ç¤ºã®textareaã§JavaScriptã‹ã‚‰éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚‹
audio_base64 = st.text_area("audio_data_textarea", value="", height=100, key="audio_data_textarea")

if audio_base64:
    st.audio(audio_base64, format="audio/wav")
    st.write("ğŸŸ¢ éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å—ä¿¡ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")

    # å‡¦ç†é–‹å§‹ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è¦‹ã›ã‚‹
    with st.spinner("è¦ç´„ã‚’ç”Ÿæˆä¸­...ãŠå¾…ã¡ãã ã•ã„ã€‚"):
        try:
            header, encoded = audio_base64.split(",", 1)
            audio_bytes = base64.b64decode(encoded)

            with BytesIO(audio_bytes) as audio_file:
                transcript = openai.Audio.transcribe("whisper-1", audio_file)

            st.write("### ğŸ“ æ–‡å­—èµ·ã“ã—çµæœ")
            st.write(transcript["text"])

            response = openai.ChatCompletion.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ä»¥ä¸‹ã®æ–‡ç« ã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚"},
                    {"role": "user", "content": transcript["text"]},
                ],
                max_tokens=200,
                temperature=0.5,
            )
            summary = response["choices"][0]["message"]["content"]
            st.write("### âœ¨ è¦ç´„")
            st.write(summary)
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
